set.seed(13435)
X <- data.frame("var1"=sample(1:5),"var2"=sample(6:10),"var3"=sample(11:15))
X <- X[sample(1:5),]; X$var2[c(1,3)] = NA
X
myapp = oauth_app("twitter", key="yourConsumerKeyHere",secret="yourConsumerSecretHere")
sig = sign_oauth1.0(myapp, token = "yourTokenHere", token_secret = "yourTokenSecretHere")
homeTL = GET("https://api.twitter.com/1.1/statuses/home_timeline.json", sig)
# convert to json object
json1 = content(homeTL)
json2 = jsonlite::fromJSON(toJSON(json1))
json2[1,1:4]
set.seed(13435)
X <- data.frame("var1"=sample(1:5),"var2"=sample(6:10),"var3"=sample(11:15))
X <- X[sample(1:5),]; X$var2[c(1,3)] = NA
X
X[(X$var1 <= 3 & X$var3 > 11),]
X[(X$var1 <= 3 | X$var3 > 15),]
X
X[which(X$var2 > 8),]
sort(X$var1)
sort(X$var1,decreasing=TRUE)
sort(X$var2,na.last=TRUE)
X[order(X$var1),]
library(plyr)
arrange(X,var1)
arrange(X,desc(var1))
X$var4 <- rnorm(5)
X
X
Y <- cbind(X,rnorm(5))
Y
if(!file.exists("./data")){dir.create("./data")}
fileUrl <- "https://data.baltimorecity.gov/api/views/k5ry-ef3g/rows.csv?accessType=DOWNLOAD"
download.file(fileUrl,destfile="./data/restaurants.csv",method="curl")
restData <- read.csv("./data/restaurants.csv")
restData
head(restData)
tail(restData)
head(restData, n = 3)
summary(restData)
str(restData)
quantile(restData$councilDistrict, na.rm = TRUE)
quantile(restData$councilDistrict, na.rm = TRUE)
quantile(restData$councilDistrict, probs = c(0.5, 0.75, 0.9))
str(restData)
table(restData$zipCode, useNA = "ifany")
table(restData$councilDistrict, restData$zipCode)
sum(is.na(restData$councilDistrict))
any(is.na(restData$councilDistrict))
all(restData$zipCode > 0)
colSums(is.na(restData))
all(colSums(is.na(restData))) == 0
all(colSums(is.na(restData)) == 0)
colSums(is.na(restData))
all(colSums(is.na(restData)) == 0)
table(restData$zipCode %in% c("21212"))
table(restData$zipCode %in% c("21212", "21213"))
table(restData$zipCode %in% c("21212", "21213"))
restData[restData$zipCode %in% c("21212", "21213"), ]
data("UCBAdmissions")
DF = as.data.frame(UCBAdmissions)
summary(DF)
xt <- xtabs(Freq ~ Gender + Admit, data = DF)
xt
head(DF)
xt
warpbreaks$replicate <- rep(1:9, len = 54)
warpbreaks$replicate <- rep(1:9, len = 54)
xt <- xtabs(breaks ~ ., data = warpbreaks)
xt
ftable(xt)
fakeData = rnorm(1e5)
object.size(fakeData)
print(object.size(fakeData), units = "Mb")
if(!file.exists("./data")){dir.create("./data")}
fileUrl <- "https://data.baltimorecity.gov/api/views/k5ry-ef3g/rows.csv?accessType=DOWNLOAD"
download.file(fileUrl,destfile="./data/restaurants.csv",method="curl")
restData <- read.csv("./data/restaurants.csv")
s1 <- seq(1,10,by=2) ; s1
s2 <- seq(1,10,length=3); s2
x <- c(1,3,8,25,100); seq(along = x)
restData$nearMe = restData$neighborhood %in% c("Roland Park", "Homeland")
table(restData$nearMe)
table(restData$zipWrong,restData$zipCode < 0)
restData$zipWrong = ifelse(restData$zipCode < 0, TRUE, FALSE)
table(restData$zipWrong,restData$zipCode < 0)
restData$zipGroups = cut(restData$zipCode, breaks=quantile(restData$zipCode))
table(restData$zipGroups)
library(Hmisc)
restData$zipGroups = cut2(restData$zipCode,g=4)
table(restData$zipGroups)
restData$zcf <- factor(restData$zipCode)
restData$zcf[1:10]
restData$zcf <- factor(restData$zipCode)
restData$zcf[1:10]
class(restData$zcf)
yesno <- sample(c("yes","no"),size=10,replace=TRUE)
yesnofac = factor(yesno,levels=c("yes","no"))
relevel(yesnofac,ref="no")
yesno <- sample(c("yes","no"), size = 10, replace = TRUE)
yesnofac = factor(yesno,levels=c("yes","no"))
yesnoface
relevel(yesnofac, ref="no")
# level of factor variable
yesno <- sample(c("yes","no"), size = 10, replace = TRUE)
yesnofac = factor(yesno,levels=c("yes","no"))
yesnoface
relevel(yesnofac, ref="no")
yesno <- sample(c("yes","no"), size = 10, replace = TRUE)
yesnofac <- factor(yesno,levels=c("yes","no"))
yesnoface
relevel(yesnofac, ref="no")
yesno <- sample(c("yes","no"), size = 10, replace = TRUE)
yesnofac <- factor(yesno,levels=c("yes","no"))
yesnoface
relevel(yesnofac, ref="no")
yesno <- sample(c("yes","no"), size = 10, replace = TRUE)
yesnofac <- factor(yesno,levels=c("yes","no"))
yesnofac
relevel(yesnofac, ref="no")
library(Hmisc)
library(Hmisc)
install.packages("Hmisc")
library(Hmisc)
restData$zipGroups = cut2(restData$zipCode, g = 4)
table(restData$zipGroups)
library(Hmisc); library(plyr)
restData2 = mutate(restData,zipGroups=cut2(zipCode,g=4))
table(restData2$zipGroups)
library(Hmisc)
install.packages("Hmisc")
library(Hmisc)
library(Hmisc)
library(plyr)
restData2 = mutate(restData,zipGroups=cut2(zipCode,g=4))
table(restData2$zipGroups)
library(reshape2)
head(mtcars)
mtcars$carname <- rownames(mtcars)
mtcars$carname
head(mtcars)
carMelt <- melt(mtcars,id=c("carname","gear","cyl"),measure.vars=c("mpg","hp"))
carMelt <- melt(mtcars,id=c("carname","gear","cyl"),measure.vars=c("mpg","hp"))
carMelt <- melt(mtcars,id.vars=c("carname","gear","cyl"),measure.vars=c("mpg","hp"))
library(reshape2)
install.packages("reshape2", repos="http://cran.rstudio.com/", dependencies=TRUE)
library(reshape2)
library(reshape2)
install.packages("reshape2", repos="http://cran.rstudio.com/", dependencies=TRUE)
library(reshape2)
head(mtcars)
library(reshape2)
install.packages("reshape2")
library(reshape2)
set.seed(13435)
x <- data.frame("var1"=sample(1:5),"var2"=sample(6:10),"var3"=sample(11:15))
x
x <- x[sample(1:5),]; x$var2[c(1,3)] = NA
x
x[1:2,"var2"]  # values(1,"var2") & values(2, "var2")
x[(x$var1 <= 3 & x$var3 > 11),]
s1 <- seq(1, 10, by=2) ; s1
s2 <- seq(1,10,length=3); s2
x <- c(1,3,8,25,100); seq(along = x)
restData$nearMe = restData$neighborhood %in% c("Roland Park", "Homeland")
table(restData$nearMe)
restData$zipWrong = ifelse(restData$zipCode < 0, TRUE, FALSE)
table(restData$zipWrong,restData$zipCode < 0)
install.packages("markdown")
install.packages("knitr")
install.packages("rmarkdown", repos="https://cloud.r-project.org")
install.packeges("xtable")
install.packeges(xtable)
#install.packages("xtable")
install.packages("xtable")
setwd("D:/GitHub/RepData_PeerAssessment2")
# load libraries
library(plyr)
library(dplyr)
library(data.table)
library(ggplot2)
# read the csv file in bz2 format
# dt <- read.csv("repdata%2Fdata%2FStormData.csv.bz2")
dt <- read.csv(bzfile("repdata%2Fdata%2FStormData.csv.bz2"))[,c(8,23,24,25,26,27,28)]
event.type <- toupper(dt$EVTYPE)
length(unique(event.type))
event.type <- gsub("[[:punct:]]", " ", event.type)
event.type <- gsub("\\d", "", event.type)
event.type <- gsub(" *$", "", event.type)
event.type <- gsub("^ *", "", event.type)
event.type <- gsub("  *", " ", event.type)
event.type[which(event.type == "")] <- "UNCLASSIFIED"
length(unique(event.type))
# update the data frame
dt$EVTYPE <- event.type
##### Types of events that are most harmful to Population Health
group.event <- group_by(dt, EVTYPE)
group.event.sum <- summarize(group.event, fats = sum(FATALITIES, na.rm = TRUE),
injs = sum(INJURIES, na.rum = TRUE))
# fatals
top.fats <- head(group.event.sum[order(group.event.sum$fats, decreasing = T), ], 10)
g <- ggplot(data = top.fats, aes(reorder(EVTYPE, fats), fats))
g + geom_bar(stat = "identity", color = "black") +
coord_flip() +
labs(y="Fatalities", x="Events",
title="Top 10 Weather Events Cause Highest Fatalities", caption = "Source: ...") +
scale_y_continuous(breaks = seq(0, 6000, by = 1000))
