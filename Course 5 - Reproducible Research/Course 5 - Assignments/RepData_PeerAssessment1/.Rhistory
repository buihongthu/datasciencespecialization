set.seed(13435)
X <- data.frame("var1"=sample(1:5),"var2"=sample(6:10),"var3"=sample(11:15))
X <- X[sample(1:5),]; X$var2[c(1,3)] = NA
X
myapp = oauth_app("twitter", key="yourConsumerKeyHere",secret="yourConsumerSecretHere")
sig = sign_oauth1.0(myapp, token = "yourTokenHere", token_secret = "yourTokenSecretHere")
homeTL = GET("https://api.twitter.com/1.1/statuses/home_timeline.json", sig)
# convert to json object
json1 = content(homeTL)
json2 = jsonlite::fromJSON(toJSON(json1))
json2[1,1:4]
set.seed(13435)
X <- data.frame("var1"=sample(1:5),"var2"=sample(6:10),"var3"=sample(11:15))
X <- X[sample(1:5),]; X$var2[c(1,3)] = NA
X
X[(X$var1 <= 3 & X$var3 > 11),]
X[(X$var1 <= 3 | X$var3 > 15),]
X
X[which(X$var2 > 8),]
sort(X$var1)
sort(X$var1,decreasing=TRUE)
sort(X$var2,na.last=TRUE)
X[order(X$var1),]
library(plyr)
arrange(X,var1)
arrange(X,desc(var1))
X$var4 <- rnorm(5)
X
X
Y <- cbind(X,rnorm(5))
Y
if(!file.exists("./data")){dir.create("./data")}
fileUrl <- "https://data.baltimorecity.gov/api/views/k5ry-ef3g/rows.csv?accessType=DOWNLOAD"
download.file(fileUrl,destfile="./data/restaurants.csv",method="curl")
restData <- read.csv("./data/restaurants.csv")
restData
head(restData)
tail(restData)
head(restData, n = 3)
summary(restData)
str(restData)
quantile(restData$councilDistrict, na.rm = TRUE)
quantile(restData$councilDistrict, na.rm = TRUE)
quantile(restData$councilDistrict, probs = c(0.5, 0.75, 0.9))
str(restData)
table(restData$zipCode, useNA = "ifany")
table(restData$councilDistrict, restData$zipCode)
sum(is.na(restData$councilDistrict))
any(is.na(restData$councilDistrict))
all(restData$zipCode > 0)
colSums(is.na(restData))
all(colSums(is.na(restData))) == 0
all(colSums(is.na(restData)) == 0)
colSums(is.na(restData))
all(colSums(is.na(restData)) == 0)
table(restData$zipCode %in% c("21212"))
table(restData$zipCode %in% c("21212", "21213"))
table(restData$zipCode %in% c("21212", "21213"))
restData[restData$zipCode %in% c("21212", "21213"), ]
data("UCBAdmissions")
DF = as.data.frame(UCBAdmissions)
summary(DF)
xt <- xtabs(Freq ~ Gender + Admit, data = DF)
xt
head(DF)
xt
warpbreaks$replicate <- rep(1:9, len = 54)
warpbreaks$replicate <- rep(1:9, len = 54)
xt <- xtabs(breaks ~ ., data = warpbreaks)
xt
ftable(xt)
fakeData = rnorm(1e5)
object.size(fakeData)
print(object.size(fakeData), units = "Mb")
if(!file.exists("./data")){dir.create("./data")}
fileUrl <- "https://data.baltimorecity.gov/api/views/k5ry-ef3g/rows.csv?accessType=DOWNLOAD"
download.file(fileUrl,destfile="./data/restaurants.csv",method="curl")
restData <- read.csv("./data/restaurants.csv")
s1 <- seq(1,10,by=2) ; s1
s2 <- seq(1,10,length=3); s2
x <- c(1,3,8,25,100); seq(along = x)
restData$nearMe = restData$neighborhood %in% c("Roland Park", "Homeland")
table(restData$nearMe)
table(restData$zipWrong,restData$zipCode < 0)
restData$zipWrong = ifelse(restData$zipCode < 0, TRUE, FALSE)
table(restData$zipWrong,restData$zipCode < 0)
restData$zipGroups = cut(restData$zipCode, breaks=quantile(restData$zipCode))
table(restData$zipGroups)
library(Hmisc)
restData$zipGroups = cut2(restData$zipCode,g=4)
table(restData$zipGroups)
restData$zcf <- factor(restData$zipCode)
restData$zcf[1:10]
restData$zcf <- factor(restData$zipCode)
restData$zcf[1:10]
class(restData$zcf)
yesno <- sample(c("yes","no"),size=10,replace=TRUE)
yesnofac = factor(yesno,levels=c("yes","no"))
relevel(yesnofac,ref="no")
yesno <- sample(c("yes","no"), size = 10, replace = TRUE)
yesnofac = factor(yesno,levels=c("yes","no"))
yesnoface
relevel(yesnofac, ref="no")
# level of factor variable
yesno <- sample(c("yes","no"), size = 10, replace = TRUE)
yesnofac = factor(yesno,levels=c("yes","no"))
yesnoface
relevel(yesnofac, ref="no")
yesno <- sample(c("yes","no"), size = 10, replace = TRUE)
yesnofac <- factor(yesno,levels=c("yes","no"))
yesnoface
relevel(yesnofac, ref="no")
yesno <- sample(c("yes","no"), size = 10, replace = TRUE)
yesnofac <- factor(yesno,levels=c("yes","no"))
yesnoface
relevel(yesnofac, ref="no")
yesno <- sample(c("yes","no"), size = 10, replace = TRUE)
yesnofac <- factor(yesno,levels=c("yes","no"))
yesnofac
relevel(yesnofac, ref="no")
library(Hmisc)
library(Hmisc)
install.packages("Hmisc")
library(Hmisc)
restData$zipGroups = cut2(restData$zipCode, g = 4)
table(restData$zipGroups)
library(Hmisc); library(plyr)
restData2 = mutate(restData,zipGroups=cut2(zipCode,g=4))
table(restData2$zipGroups)
library(Hmisc)
install.packages("Hmisc")
library(Hmisc)
library(Hmisc)
library(plyr)
restData2 = mutate(restData,zipGroups=cut2(zipCode,g=4))
table(restData2$zipGroups)
library(reshape2)
head(mtcars)
mtcars$carname <- rownames(mtcars)
mtcars$carname
head(mtcars)
carMelt <- melt(mtcars,id=c("carname","gear","cyl"),measure.vars=c("mpg","hp"))
carMelt <- melt(mtcars,id=c("carname","gear","cyl"),measure.vars=c("mpg","hp"))
carMelt <- melt(mtcars,id.vars=c("carname","gear","cyl"),measure.vars=c("mpg","hp"))
library(reshape2)
install.packages("reshape2", repos="http://cran.rstudio.com/", dependencies=TRUE)
library(reshape2)
library(reshape2)
install.packages("reshape2", repos="http://cran.rstudio.com/", dependencies=TRUE)
library(reshape2)
head(mtcars)
library(reshape2)
install.packages("reshape2")
library(reshape2)
set.seed(13435)
x <- data.frame("var1"=sample(1:5),"var2"=sample(6:10),"var3"=sample(11:15))
x
x <- x[sample(1:5),]; x$var2[c(1,3)] = NA
x
x[1:2,"var2"]  # values(1,"var2") & values(2, "var2")
x[(x$var1 <= 3 & x$var3 > 11),]
s1 <- seq(1, 10, by=2) ; s1
s2 <- seq(1,10,length=3); s2
x <- c(1,3,8,25,100); seq(along = x)
restData$nearMe = restData$neighborhood %in% c("Roland Park", "Homeland")
table(restData$nearMe)
restData$zipWrong = ifelse(restData$zipCode < 0, TRUE, FALSE)
table(restData$zipWrong,restData$zipCode < 0)
install.packages("markdown")
install.packages("knitr")
install.packages("rmarkdown", repos="https://cloud.r-project.org")
install.packeges("xtable")
install.packeges(xtable)
#install.packages("xtable")
install.packages("xtable")
library(ggplot2)
g <- ggplot(steps.itv.date_type, aes(interval, steps))
g +  facet_grid(. ~ isweekend) + geom_line(linetype = "solid")
df <- read.csv("activity.csv", header = TRUE, sep = ",")
library(lubridate)
df$date <- ymd(df$date)
library(dplyr)
dates <- group_by(df, date)
steps.sum.date <- summarize(dates, steps = sum(steps, na.rm = TRUE))
# 2. histogram of total number of steps taken each day
hist(steps.sum.date$steps, breaks = 5, main = "Total steps per day", xlab = "Steps")
# 3. mean and median number of steps taken each day
mean(steps.sum.date$steps)
median(steps.sum.date$steps)
# 4. time series plot of the average number of steps taken
itvs <- group_by(df, interval)
steps.avg.itv <- summarize(itvs, steps= mean(steps, na.rm = TRUE))
plot(steps.avg.itv$interval, steps.avg.itv$steps, type="l",
main = "Average number of steps taken during intervals",
xlab = "5-minute interval", ylab = "Average number of steps")
# 5. the 5-minute interval that, on average, contains the maximum number of steps
max_steps <- steps.avg.itv[which.max(steps.avg.itv$steps),]
# 6. code to describe and show a strategy for imputing missing data
# mean steps of date
itv.mean <- function(itv){
steps.avg.itv[steps.avg.itv$interval == itv,"steps"]
}
# create a new dataset that is equal to the original dataset but with the missing data filled in.
dff <- df
for (i in 1:nrow(dff)) {
if (is.na(dff[i,"steps"])) {
dff[i,"steps"] <- ceiling(itv.mean(dff[i,"interval"]))
}
}
# 7. histogram of the total number of steps taken each day after missing values are imputed
# group dataset by date
dates <- group_by(dff, date)
# sum of steps by dates
steps.sum.date <- summarize(dates, steps = sum(steps, na.rm = TRUE))
# histogram
hist(steps.sum.date$steps, breaks = 5, main = "Total steps per day", xlab = "Steps")
# 8. panel plot comparing the average number of steps taken per 5-minute interval across weekdays and weekends
# create new variable of weekday
dff$weekday <- factor(weekdays(dff$date)) # weekdays
# create new variable of isweekend
dff <- mutate(dff, isweekend = factor(weekday %in% c("Saturday", "Sunday"), levels = c(TRUE, FALSE), labels = c("weekends","weekdays")))
# sum of steps on interval separated by date type
steps.itv.date_type = aggregate(steps ~ interval + isweekend, dff, mean)
# draw two graphs separated by date type
library(ggplot2)
g <- ggplot(steps.itv.date_type, aes(interval, steps))
g +  facet_grid(. ~ isweekend) + geom_line(linetype = "solid")
setwd("D:/GitHub/RepData_PeerAssessment1")
df <- read.csv("activity.csv", header = TRUE, sep = ",")
library(lubridate)
df$date <- ymd(df$date)
library(dplyr)
dates <- group_by(df, date)
steps.sum.date <- summarize(dates, steps = sum(steps, na.rm = TRUE))
# 2. histogram of total number of steps taken each day
hist(steps.sum.date$steps, breaks = 5, main = "Total steps per day", xlab = "Steps")
# 3. mean and median number of steps taken each day
mean(steps.sum.date$steps)
median(steps.sum.date$steps)
# 4. time series plot of the average number of steps taken
itvs <- group_by(df, interval)
steps.avg.itv <- summarize(itvs, steps= mean(steps, na.rm = TRUE))
plot(steps.avg.itv$interval, steps.avg.itv$steps, type="l",
main = "Average number of steps taken during intervals",
xlab = "5-minute interval", ylab = "Average number of steps")
# 5. the 5-minute interval that, on average, contains the maximum number of steps
max_steps <- steps.avg.itv[which.max(steps.avg.itv$steps),]
# 6. code to describe and show a strategy for imputing missing data
# mean steps of date
itv.mean <- function(itv){
steps.avg.itv[steps.avg.itv$interval == itv,"steps"]
}
# create a new dataset that is equal to the original dataset but with the missing data filled in.
dff <- df
for (i in 1:nrow(dff)) {
if (is.na(dff[i,"steps"])) {
dff[i,"steps"] <- ceiling(itv.mean(dff[i,"interval"]))
}
}
# 7. histogram of the total number of steps taken each day after missing values are imputed
# group dataset by date
dates <- group_by(dff, date)
# sum of steps by dates
steps.sum.date <- summarize(dates, steps = sum(steps, na.rm = TRUE))
# histogram
hist(steps.sum.date$steps, breaks = 5, main = "Total steps per day", xlab = "Steps")
# 8. panel plot comparing the average number of steps taken per 5-minute interval across weekdays and weekends
# create new variable of weekday
dff$weekday <- factor(weekdays(dff$date)) # weekdays
# create new variable of isweekend
dff <- mutate(dff, isweekend = factor(weekday %in% c("Saturday", "Sunday"), levels = c(TRUE, FALSE), labels = c("weekends","weekdays")))
# sum of steps on interval separated by date type
steps.itv.date_type = aggregate(steps ~ interval + isweekend, dff, mean)
# draw two graphs separated by date type
library(ggplot2)
g <- ggplot(steps.itv.date_type, aes(interval, steps))
g +  facet_grid(. ~ isweekend) + geom_line(linetype = "solid")
df <- read.csv("activity.csv", header = TRUE, sep = ",")
setwd("D:/GitHub/RepData_PeerAssessment1")
df <- read.csv("activity.csv", header = TRUE, sep = ",")
library(lubridate)
df$date <- ymd(df$date)
knit2html("PA1_template.Rmd")
library(knitr)
knit2html("PA1_template.Rmd")
knit2html("PA1_template.Rmd")
render("PA1_template.Rmd")
library(rmarkdown)
render("PA1_template.Rmd")
render("PA1_template.Rmd")
