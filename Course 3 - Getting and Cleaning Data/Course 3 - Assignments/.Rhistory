set.seed(13435)
X <- data.frame("var1"=sample(1:5),"var2"=sample(6:10),"var3"=sample(11:15))
X <- X[sample(1:5),]; X$var2[c(1,3)] = NA
X
myapp = oauth_app("twitter", key="yourConsumerKeyHere",secret="yourConsumerSecretHere")
sig = sign_oauth1.0(myapp, token = "yourTokenHere", token_secret = "yourTokenSecretHere")
homeTL = GET("https://api.twitter.com/1.1/statuses/home_timeline.json", sig)
# convert to json object
json1 = content(homeTL)
json2 = jsonlite::fromJSON(toJSON(json1))
json2[1,1:4]
set.seed(13435)
X <- data.frame("var1"=sample(1:5),"var2"=sample(6:10),"var3"=sample(11:15))
X <- X[sample(1:5),]; X$var2[c(1,3)] = NA
X
X[(X$var1 <= 3 & X$var3 > 11),]
X[(X$var1 <= 3 | X$var3 > 15),]
X
X[which(X$var2 > 8),]
sort(X$var1)
sort(X$var1,decreasing=TRUE)
sort(X$var2,na.last=TRUE)
X[order(X$var1),]
library(plyr)
arrange(X,var1)
arrange(X,desc(var1))
X$var4 <- rnorm(5)
X
X
Y <- cbind(X,rnorm(5))
Y
if(!file.exists("./data")){dir.create("./data")}
fileUrl <- "https://data.baltimorecity.gov/api/views/k5ry-ef3g/rows.csv?accessType=DOWNLOAD"
download.file(fileUrl,destfile="./data/restaurants.csv",method="curl")
restData <- read.csv("./data/restaurants.csv")
restData
head(restData)
tail(restData)
head(restData, n = 3)
summary(restData)
str(restData)
quantile(restData$councilDistrict, na.rm = TRUE)
quantile(restData$councilDistrict, na.rm = TRUE)
quantile(restData$councilDistrict, probs = c(0.5, 0.75, 0.9))
str(restData)
table(restData$zipCode, useNA = "ifany")
table(restData$councilDistrict, restData$zipCode)
sum(is.na(restData$councilDistrict))
any(is.na(restData$councilDistrict))
all(restData$zipCode > 0)
colSums(is.na(restData))
all(colSums(is.na(restData))) == 0
all(colSums(is.na(restData)) == 0)
colSums(is.na(restData))
all(colSums(is.na(restData)) == 0)
table(restData$zipCode %in% c("21212"))
table(restData$zipCode %in% c("21212", "21213"))
table(restData$zipCode %in% c("21212", "21213"))
restData[restData$zipCode %in% c("21212", "21213"), ]
data("UCBAdmissions")
DF = as.data.frame(UCBAdmissions)
summary(DF)
xt <- xtabs(Freq ~ Gender + Admit, data = DF)
xt
head(DF)
xt
warpbreaks$replicate <- rep(1:9, len = 54)
warpbreaks$replicate <- rep(1:9, len = 54)
xt <- xtabs(breaks ~ ., data = warpbreaks)
xt
ftable(xt)
fakeData = rnorm(1e5)
object.size(fakeData)
print(object.size(fakeData), units = "Mb")
if(!file.exists("./data")){dir.create("./data")}
fileUrl <- "https://data.baltimorecity.gov/api/views/k5ry-ef3g/rows.csv?accessType=DOWNLOAD"
download.file(fileUrl,destfile="./data/restaurants.csv",method="curl")
restData <- read.csv("./data/restaurants.csv")
s1 <- seq(1,10,by=2) ; s1
s2 <- seq(1,10,length=3); s2
x <- c(1,3,8,25,100); seq(along = x)
restData$nearMe = restData$neighborhood %in% c("Roland Park", "Homeland")
table(restData$nearMe)
table(restData$zipWrong,restData$zipCode < 0)
restData$zipWrong = ifelse(restData$zipCode < 0, TRUE, FALSE)
table(restData$zipWrong,restData$zipCode < 0)
restData$zipGroups = cut(restData$zipCode, breaks=quantile(restData$zipCode))
table(restData$zipGroups)
library(Hmisc)
restData$zipGroups = cut2(restData$zipCode,g=4)
table(restData$zipGroups)
restData$zcf <- factor(restData$zipCode)
restData$zcf[1:10]
restData$zcf <- factor(restData$zipCode)
restData$zcf[1:10]
class(restData$zcf)
yesno <- sample(c("yes","no"),size=10,replace=TRUE)
yesnofac = factor(yesno,levels=c("yes","no"))
relevel(yesnofac,ref="no")
yesno <- sample(c("yes","no"), size = 10, replace = TRUE)
yesnofac = factor(yesno,levels=c("yes","no"))
yesnoface
relevel(yesnofac, ref="no")
# level of factor variable
yesno <- sample(c("yes","no"), size = 10, replace = TRUE)
yesnofac = factor(yesno,levels=c("yes","no"))
yesnoface
relevel(yesnofac, ref="no")
yesno <- sample(c("yes","no"), size = 10, replace = TRUE)
yesnofac <- factor(yesno,levels=c("yes","no"))
yesnoface
relevel(yesnofac, ref="no")
yesno <- sample(c("yes","no"), size = 10, replace = TRUE)
yesnofac <- factor(yesno,levels=c("yes","no"))
yesnoface
relevel(yesnofac, ref="no")
yesno <- sample(c("yes","no"), size = 10, replace = TRUE)
yesnofac <- factor(yesno,levels=c("yes","no"))
yesnofac
relevel(yesnofac, ref="no")
library(Hmisc)
library(Hmisc)
install.packages("Hmisc")
library(Hmisc)
restData$zipGroups = cut2(restData$zipCode, g = 4)
table(restData$zipGroups)
library(Hmisc); library(plyr)
restData2 = mutate(restData,zipGroups=cut2(zipCode,g=4))
table(restData2$zipGroups)
library(Hmisc)
install.packages("Hmisc")
library(Hmisc)
library(Hmisc)
library(plyr)
restData2 = mutate(restData,zipGroups=cut2(zipCode,g=4))
table(restData2$zipGroups)
library(reshape2)
head(mtcars)
mtcars$carname <- rownames(mtcars)
mtcars$carname
head(mtcars)
carMelt <- melt(mtcars,id=c("carname","gear","cyl"),measure.vars=c("mpg","hp"))
carMelt <- melt(mtcars,id=c("carname","gear","cyl"),measure.vars=c("mpg","hp"))
carMelt <- melt(mtcars,id.vars=c("carname","gear","cyl"),measure.vars=c("mpg","hp"))
library(reshape2)
install.packages("reshape2", repos="http://cran.rstudio.com/", dependencies=TRUE)
library(reshape2)
library(reshape2)
install.packages("reshape2", repos="http://cran.rstudio.com/", dependencies=TRUE)
library(reshape2)
head(mtcars)
library(reshape2)
install.packages("reshape2")
library(reshape2)
set.seed(13435)
x <- data.frame("var1"=sample(1:5),"var2"=sample(6:10),"var3"=sample(11:15))
x
x <- x[sample(1:5),]; x$var2[c(1,3)] = NA
x
x[1:2,"var2"]  # values(1,"var2") & values(2, "var2")
x[(x$var1 <= 3 & x$var3 > 11),]
s1 <- seq(1, 10, by=2) ; s1
s2 <- seq(1,10,length=3); s2
x <- c(1,3,8,25,100); seq(along = x)
restData$nearMe = restData$neighborhood %in% c("Roland Park", "Homeland")
table(restData$nearMe)
restData$zipWrong = ifelse(restData$zipCode < 0, TRUE, FALSE)
table(restData$zipWrong,restData$zipCode < 0)
swirl()
library(swirl)
swirl()
librara(tidyr)
library(tidyr)
students
?gather
gather(students, sex, count, -grade)
studens2
students2
?gather
res <- gather(students2, sex_class, count, -grade)
res
?separate
separate(data = ress, col = sex_class, into = c("sex", "class"))
separate(data = res, col = sex_class, into = c("sex", "class"))
submit()
students3
submit()
?spread
submit()
library(readr)
parse_number("class5")
submit()
students4
submit()
submit()
submit()
passed
failed
> passed <- passed %>% mutate(status="passed")
passed <- passed %>% mutate(status="passed")
failed <- failed %>% mutate(status="failed")
?bind_rows
bind_rows(passed,failed)
sat
?select
?separate
submit()
submit()
submit()
submit()
reset()
swirl()
submit()
submit()
submit()
submit()
Sys.getlocale("LC_TIME")
library(lubridate)
help(package = lubridate)
today()
this_day <- today()
this_day
year(this_day)
wday(this_day)
wday(this_day, label = TRUE)
this_moment <- now()
this_moment
hour(this_moment)
ymd("1989-05-17")
my_date <- ymd("1989-05-17")
my_date
class(my_date)
ymd("1989 May 17")
mdy("March 12, 1975")
dmy(25081985)
ymd("192012")
ymd("1220-1-2)
""
ymd()
q
exit()
""
ymd("1920-1-2")
dt1
ymd_hms(dt1)
hms("03:22:14")
dt2
ymd(dt2)
update(this_moment, hours = 8, minutes = 34, seconds = 55)
this_moment
update(this_moment, hours = 11, minutes = 55, seconds = 0)
update(this_moment, hours = 10, minutes = 16, seconds = 0)
this_moment <- update(this_moment, hours = 10, minutes = 16, seconds = 0)
this_moment
now()
now("America/New_York")
nyc <- now("America/New_York")
nyc
depart <- nyc + days(2)
depart
depart <- update(depart, hours = 17, minutes = 34)
depart
arrive <- depart + hour(15) + minute(50)
arrive <- depart + hours(15) + minutes(50)
?with_tz
arrive <- with_tz(arrive, tzone = "Asia/Hong_Kong")
arrive
last_time <- mdy("June 17, 2008")
last_time <- mdy("June 17, 2008", tz = "Singapore")
last_time
?interval
how_long <- interval(last_time, arrive)
as.period(how_long)
stopwatch()
com <- read.csv("./data/hi.csv")
setwd("D:/GitHub/datasciencespecialization/Course 3 - Getting and Cleaning Data/Course 3 - Lessons")
setwd("D:/GitHub/datasciencespecialization/Course 3 - Getting and Cleaning Data/Course 3 - Lessons")
com <- read.csv("./data/hi.csv")
head(com)
a <- strsplit(com, "wgtp")
a <- strsplit(names(com), "wgtp")
a[123]
setwd("D:/GitHub/datasciencespecialization/Course 3 - Getting and Cleaning Data/Course 3 - Assignments")
if (!file.exists("getdata_dataset.zip")){
fileURL <- "https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip "
download.file(fileURL, filename, method="curl")
}
if (!file.exists("UCI HAR Dataset")) {
unzip(filename)
}
if (!file.exists("getdata_dataset.zip")){
fileURL <- "https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip "
download.file(fileURL, "getdata_dataset.zip", method="curl")
}
if (!file.exists("UCI HAR Dataset")) {
unzip(filename)
}
activityLabels <- read.table("UCI HAR Dataset/activity_labels.txt")
activityLabels[,2] <- as.character(activityLabels[,2])
features <- read.table("UCI HAR Dataset/features.txt")
features[,2] <- as.character(features[,2])
activityLabels
activityLabels <- read.table("UCI HAR Dataset/activity_labels.txt")
activityLabels
activityLabels[,2] <- as.character(activityLabels[,2])
activityLabels
features <- read.table("UCI HAR Dataset/features.txt")
features
features[,2] <- as.character(features[,2])
featuresWanted <- grep(".*mean.*|.*std.*", features[,2])
featuresWanted
featuresWanted.names <- features[featuresWanted,2]
featuresWanted.names
featuresWanted.names = gsub('-mean', 'Mean', featuresWanted.names)
featuresWanted.names
featuresWanted.names = gsub('-std', 'Std', featuresWanted.names)
featuresWanted.names <- gsub('[-()]', '', featuresWanted.names)
featuresWanted.names
featuresWanted.names
# Load activity labels + features
activityLabels <- read.table("UCI HAR Dataset/activity_labels.txt")
activityLabels[,2] <- as.character(activityLabels[,2])
features <- read.table("UCI HAR Dataset/features.txt")
features[,2] <- as.character(features[,2])
# Extract only the data on mean and standard deviation
featuresWanted <- grep(".*mean.*|.*std.*", features[,2])
featuresWanted.names <- features[featuresWanted,2]
featuresWanted.names = gsub('-mean', 'Mean', featuresWanted.names)
featuresWanted.names = gsub('-std', 'Std', featuresWanted.names)
featuresWanted.names <- gsub('[-()]', '', featuresWanted.names)
# Load the datasets
train <- read.table("UCI HAR Dataset/train/X_train.txt")[featuresWanted]
trainActivities <- read.table("UCI HAR Dataset/train/Y_train.txt")
trainSubjects <- read.table("UCI HAR Dataset/train/subject_train.txt")
train <- cbind(trainSubjects, trainActivities, train)
test <- read.table("UCI HAR Dataset/test/X_test.txt")[featuresWanted]
testActivities <- read.table("UCI HAR Dataset/test/Y_test.txt")
testSubjects <- read.table("UCI HAR Dataset/test/subject_test.txt")
test <- cbind(testSubjects, testActivities, test)
# merge datasets and add labels
allData <- rbind(train, test)
colnames(allData) <- c("subject", "activity", featuresWanted.names)
# turn activities & subjects into factors
allData$activity <- factor(allData$activity, levels = activityLabels[,1], labels = activityLabels[,2])
allData$subject <- as.factor(allData$subject)
allData.melted <- melt(allData, id = c("subject", "activity"))
allData.mean <- dcast(allData.melted, subject + activity ~ variable, mean)
write.table(allData.mean, "tidy.txt", row.names = FALSE, quote = FALSE)
library(reshape2)
allData.melted <- melt(allData, id = c("subject", "activity"))
allData.mean <- dcast(allData.melted, subject + activity ~ variable, mean)
write.table(allData.mean, "tidy.txt", row.names = FALSE, quote = FALSE)
featuresWanted.names
train <- read.table("UCI HAR Dataset/train/X_train.txt")[featuresWanted]
train
trainActivities <- read.table("UCI HAR Dataset/train/Y_train.txt")
trainSubjects <- read.table("UCI HAR Dataset/train/subject_train.txt")
trainActivities
trainSubjects
train <- cbind(trainSubjects, trainActivities, train)
train
test <- read.table("UCI HAR Dataset/test/X_test.txt")[featuresWanted]
testActivities <- read.table("UCI HAR Dataset/test/Y_test.txt")
testSubjects <- read.table("UCI HAR Dataset/test/subject_test.txt")
test <- cbind(testSubjects, testActivities, test)
test
allData <- rbind(train, test)
colnames(allData) <- c("subject", "activity", featuresWanted.names)
allData
allData$activity <- factor(allData$activity, levels = activityLabels[,1], labels = activityLabels[,2])
allData$subject <- as.factor(allData$subject)
allData.melted <- melt(allData, id = c("subject", "activity"))
allData.mean <- dcast(allData.melted, subject + activity ~ variable, mean)
allData.mean
write.table(allData.mean, "tidy.txt", row.names = FALSE, quote = FALSE)
allData.mean
allData.melted
